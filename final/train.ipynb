{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c120f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "517bd422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'arp poisoning': 1, 'dictionary ssh': 2, 'tcp ddos': 3}\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"] = df[\"label\"].astype(str).str.strip().str.lower()\n",
    "all_labels = sorted(df[\"label\"].unique())\n",
    "attack_labels = [lbl for lbl in all_labels if lbl != \"normal\"]\n",
    "label_map = {\"normal\": 0}\n",
    "label_map.update({lbl: i + 1 for i, lbl in enumerate(attack_labels)})\n",
    "\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_encoded\"] = df[\"label\"].map(lambda x: label_map.get(x, 0)).astype(np.int64)\n",
    "\n",
    "df = df.replace(r\"^\\s*$\", np.nan, regex=True).fillna(0)\n",
    "feature_df = df.drop(columns=[\"label\", \"label_encoded\"], errors=\"ignore\").select_dtypes(\n",
    "    include=[np.number]\n",
    ")\n",
    "labels = df[\"label_encoded\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4488b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    'frame.len',\n",
    "    'frame.protocols',\n",
    "\n",
    "    'ip.len',\n",
    "    'ip.ttl',\n",
    "    'ip.id',\n",
    "    'ip.proto',\n",
    "\n",
    "    'tcp.srcport',\n",
    "    'tcp.dstport',\n",
    "    'tcp.len',\n",
    "    'tcp.flags',\n",
    "    'tcp.window_size',\n",
    "    'tcp.options.timestamp.tsval',\n",
    "    'tcp.options.wscale.shift',\n",
    "\n",
    "    'udp.srcport',\n",
    "    'udp.dstport',\n",
    "    'udp.length',\n",
    "\n",
    "    'dns.flags.response',\n",
    "    'dns.flags.rcode',\n",
    "    'dns.qry.type',\n",
    "\n",
    "    'tls.record.content_type',\n",
    "\n",
    "    'delta_time',\n",
    "\n",
    "    # Missing indicators\n",
    "    'delta_time__miss',\n",
    "    'tcp.len__miss',\n",
    "    'tcp.window_size__miss',\n",
    "    'tcp.options.timestamp.tsval__miss',\n",
    "    'udp.length__miss',\n",
    "\n",
    "    # And your target label (keep it if present)\n",
    "    'label'\n",
    "]\n",
    "\n",
    "df = df[ [col for col in keep_cols if col in df.columns] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b32766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520235, 27)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca72eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame.len                                  0\n",
       "frame.protocols                            0\n",
       "ip.len                                     0\n",
       "ip.ttl                                     0\n",
       "ip.id                                1520235\n",
       "ip.proto                                   0\n",
       "tcp.srcport                                0\n",
       "tcp.dstport                                0\n",
       "tcp.len                                    0\n",
       "tcp.flags                                  0\n",
       "tcp.window_size                            0\n",
       "tcp.options.timestamp.tsval           499974\n",
       "tcp.options.wscale.shift             1024995\n",
       "udp.srcport                           499974\n",
       "udp.dstport                           499974\n",
       "udp.length                            499974\n",
       "dns.flags.response                    499974\n",
       "dns.flags.rcode                       995214\n",
       "dns.qry.type                          499974\n",
       "tls.record.content_type              1023504\n",
       "delta_time                                 0\n",
       "delta_time__miss                           0\n",
       "tcp.len__miss                              0\n",
       "tcp.window_size__miss                      0\n",
       "tcp.options.timestamp.tsval__miss     499974\n",
       "udp.length__miss                      499974\n",
       "label                                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567fcf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    feature_df, labels, test_size=0.2, random_state=32, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d421fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train.astype(np.float32))\n",
    "x_test_scaled = scaler.transform(x_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d48e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "feature_names = list(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0184416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkEnv import IDSEnvironment\n",
    "from config import *\n",
    "\n",
    "# Use scaled numpy arrays instead of DataFrames to avoid conversion issues\n",
    "train_env = IDSEnvironment(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    n_features=n_features,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    max_steps=MAX_STEPS_PER_EPISODE,\n",
    ")\n",
    "test_env = IDSEnvironment(\n",
    "    x_test_scaled,\n",
    "    y_test,\n",
    "    n_features=n_features,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    max_steps=len(x_test_scaled) - 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e52304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "def save_checkpoint(agent, episode, episode_rewards, filename):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    checkpoint = {\n",
    "        \"episode\": episode,\n",
    "        \"policy_net_state_dict\": agent.policy_net.state_dict(),\n",
    "        \"target_net_state_dict\": agent.target_net.state_dict(),\n",
    "        \"optimizer_state_dict\": agent.optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": (\n",
    "            agent.scheduler.state_dict() if hasattr(agent, \"scheduler\") else None\n",
    "        ),\n",
    "        \"episode_rewards\": episode_rewards,\n",
    "        \"steps_done\": agent.steps_done,\n",
    "        \"memory\": agent.memory,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved: {filename}\")\n",
    "\n",
    "\n",
    "def load_latest_checkpoint(agent, checkpoint_dir):\n",
    "    \"\"\"Load the latest checkpoint\"\"\"\n",
    "    checkpoint_files = glob.glob(\n",
    "        os.path.join(checkpoint_dir, \"checkpoint_episode_*.pth\")\n",
    "    )\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoints found. Starting from scratch.\")\n",
    "        return 0, []\n",
    "\n",
    "    # Get the latest checkpoint\n",
    "    latest_checkpoint = max(\n",
    "        checkpoint_files, key=lambda x: int(x.split(\"_episode_\")[1].split(\".pth\")[0])\n",
    "    )\n",
    "\n",
    "    print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
    "    checkpoint = torch.load(latest_checkpoint,weights_only=False)\n",
    "\n",
    "    # Load model states\n",
    "    agent.policy_net.load_state_dict(checkpoint[\"policy_net_state_dict\"])\n",
    "    agent.target_net.load_state_dict(checkpoint[\"target_net_state_dict\"])\n",
    "    agent.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    if checkpoint[\"scheduler_state_dict\"] and hasattr(agent, \"scheduler\"):\n",
    "        agent.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "    # Load training state\n",
    "    agent.steps_done = checkpoint[\"steps_done\"]\n",
    "    agent.memory = checkpoint[\"memory\"]\n",
    "\n",
    "    start_episode = checkpoint[\"episode\"] + 1\n",
    "    episode_rewards = checkpoint[\"episode_rewards\"]\n",
    "\n",
    "    print(f\"Resumed from episode {start_episode}\")\n",
    "    return start_episode, episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cef8912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./checkpoints/checkpoint_episode_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/IDS/.conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'v'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m agent \u001b[38;5;241m=\u001b[39m DTQNAgent(n_features\u001b[38;5;241m=\u001b[39mn_features, n_actions\u001b[38;5;241m=\u001b[39mtrain_env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Load latest checkpoint if available\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m start_episode, episode_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mload_latest_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_episode, NUM_EPISODES):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m, in \u001b[0;36mload_latest_checkpoint\u001b[0;34m(agent, checkpoint_dir)\u001b[0m\n\u001b[1;32m     34\u001b[0m latest_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m     35\u001b[0m     checkpoint_files, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_episode_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatest_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load model states\u001b[39;00m\n\u001b[1;32m     42\u001b[0m agent\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_net_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/IDS/.conda/lib/python3.10/site-packages/torch/serialization.py:1554\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IDS/.conda/lib/python3.10/site-packages/torch/serialization.py:1802\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# if not a tarfile, reset file offset and proceed\u001b[39;00m\n\u001b[1;32m   1800\u001b[0m         f\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1802\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from agent import DTQNAgent\n",
    "\n",
    "# Create checkpoints directory\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize agent\n",
    "agent = DTQNAgent(n_features=n_features, n_actions=train_env.action_space.n)\n",
    "\n",
    "# Load latest checkpoint if available\n",
    "start_episode, episode_rewards = load_latest_checkpoint(agent, checkpoint_dir)\n",
    "\n",
    "for i_episode in range(start_episode, NUM_EPISODES):\n",
    "\n",
    "    start_time = time.time()\n",
    "    state = train_env.reset()\n",
    "    episode_reward = 0\n",
    "\n",
    "    # Track metrics for this episode\n",
    "    episode_actions = []\n",
    "    episode_true_labels = []\n",
    "    episode_rewards_list = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Progress bar for steps within each episode\n",
    "    step_pbar = tqdm(\n",
    "        range(MAX_STEPS_PER_EPISODE),\n",
    "        desc=f\"DTQN Episode {i_episode+1} Steps\",\n",
    "        leave=False,\n",
    "        unit=\"step\",\n",
    "    )\n",
    "\n",
    "    for t in step_pbar:\n",
    "        # Select and perform an action - no need for .values since state is already numpy array\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, true_label = train_env.step(action.item())\n",
    "\n",
    "        # Track metrics\n",
    "        episode_actions.append(action.item())\n",
    "        episode_true_labels.append(true_label)\n",
    "        episode_rewards_list.append(reward)\n",
    "\n",
    "        if action.item() == true_label:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Store the transition in memory - no need for DataFrame conversion\n",
    "        agent.memory.push(state, action, next_state, reward, done)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        agent.optimize_model()\n",
    "\n",
    "        # Update step progress bar with current reward and accuracy\n",
    "        current_accuracy = (\n",
    "            correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "        )\n",
    "        step_pbar.set_postfix(\n",
    "            {\n",
    "                \"Reward\": f\"{episode_reward:.2f}\",\n",
    "                \"Acc\": f\"{current_accuracy:.3f}\",\n",
    "                \"Step\": t + 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if done:\n",
    "            step_pbar.close()\n",
    "            break\n",
    "    else:\n",
    "        step_pbar.close()\n",
    "\n",
    "    episode_rewards.append(episode_reward)\n",
    "    elapsed_time = (time.time() - start_time) / 60.0\n",
    "\n",
    "    # Calculate episode metrics\n",
    "    episode_accuracy = (\n",
    "        correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calculate multi-class confusion matrix elements\n",
    "    n_classes = len(set(episode_true_labels + episode_actions))\n",
    "\n",
    "    # Calculate per-class metrics for training episode\n",
    "    class_metrics = {}\n",
    "    for class_id in range(n_classes):\n",
    "        tp = sum(\n",
    "            1\n",
    "            for pred, true in zip(episode_actions, episode_true_labels)\n",
    "            if pred == class_id and true == class_id\n",
    "        )\n",
    "        tn = sum(\n",
    "            1\n",
    "            for pred, true in zip(episode_actions, episode_true_labels)\n",
    "            if pred != class_id and true != class_id\n",
    "        )\n",
    "        fp = sum(\n",
    "            1\n",
    "            for pred, true in zip(episode_actions, episode_true_labels)\n",
    "            if pred == class_id and true != class_id\n",
    "        )\n",
    "        fn = sum(\n",
    "            1\n",
    "            for pred, true in zip(episode_actions, episode_true_labels)\n",
    "            if pred != class_id and true == class_id\n",
    "        )\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = (\n",
    "            2 * (precision * recall) / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        class_metrics[class_id] = {\n",
    "            \"tp\": tp,\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "        }\n",
    "\n",
    "    # Overall metrics (macro-average)\n",
    "    precision = (\n",
    "        np.mean([class_metrics[i][\"precision\"] for i in class_metrics])\n",
    "        if class_metrics\n",
    "        else 0\n",
    "    )\n",
    "    recall = (\n",
    "        np.mean([class_metrics[i][\"recall\"] for i in class_metrics])\n",
    "        if class_metrics\n",
    "        else 0\n",
    "    )\n",
    "    f1_score = (\n",
    "        np.mean([class_metrics[i][\"f1_score\"] for i in class_metrics])\n",
    "        if class_metrics\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # False Positive Rate for normal class (class 0)\n",
    "    normal_fp = class_metrics.get(0, {}).get(\"fp\", 0)\n",
    "    normal_tn = class_metrics.get(0, {}).get(\"tn\", 0)\n",
    "    fpr = normal_fp / (normal_fp + normal_tn) if (normal_fp + normal_tn) > 0 else 0\n",
    "\n",
    "    # Calculate epsilon value for exploration tracking\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(\n",
    "        -1.0 * agent.steps_done / EPS_DECAY\n",
    "    )\n",
    "\n",
    "    # Calculate moving averages\n",
    "    avg_reward_10 = (\n",
    "        np.mean(episode_rewards[-10:])\n",
    "        if len(episode_rewards) >= 10\n",
    "        else np.mean(episode_rewards)\n",
    "    )\n",
    "    avg_reward_100 = (\n",
    "        np.mean(episode_rewards[-100:])\n",
    "        if len(episode_rewards) >= 100\n",
    "        else np.mean(episode_rewards)\n",
    "    )\n",
    "\n",
    "    # Get current learning rate\n",
    "    current_lr = (\n",
    "        agent.scheduler.get_last_lr()[0]\n",
    "        if hasattr(agent.scheduler, \"get_last_lr\")\n",
    "        else LR\n",
    "    )\n",
    "\n",
    "    # Perform quick validation with more thorough sampling\n",
    "    val_metrics = agent.quick_validation(\n",
    "        test_env, max_samples=2000\n",
    "    )  # Increased sample size\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    # Print comprehensive episode metrics\n",
    "    print(f\"Episode {i_episode + 1} Complete:\")\n",
    "    print(\n",
    "        f\"Performance: Reward={episode_reward:.2f}, Steps={t+1}, Time={elapsed_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "    # Training Metrics\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"TRAINING METRICS:\")\n",
    "    print(\n",
    "        f\"Accuracy: {episode_accuracy:.3f} | Precision: {precision:.3f} | Recall: {recall:.3f} | F1: {f1_score:.3f}\"\n",
    "    )\n",
    "    print(f\"False Positive Rate (Normal): {fpr:.3f}\")\n",
    "\n",
    "    # Show per-class performance for training\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    print(f\" Per-Class Training Results:\")\n",
    "    for class_id in class_metrics:\n",
    "        class_name = reverse_label_map.get(class_id, f\"Class_{class_id}\")\n",
    "        cm = class_metrics[class_id]\n",
    "        print(\n",
    "            f\"         {class_name}: P={cm['precision']:.3f}, R={cm['recall']:.3f}, F1={cm['f1_score']:.3f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    # Validation Metrics\n",
    "    print(f\"VALIDATION METRICS:\")\n",
    "    print(\n",
    "        f\"Accuracy: {val_metrics['accuracy']:.3f} | Precision: {val_metrics['precision']:.3f} | Recall: {val_metrics['recall']:.3f} | F1: {val_metrics['f1_score']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"False Positive Rate (Normal): {val_metrics['fpr']:.3f} | Avg Reward: {val_metrics['reward']:.2f}\"\n",
    "    )\n",
    "    print(f\"Samples Tested: {val_metrics['samples']}\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    # Show per-class performance for validation\n",
    "    print(f\"Per-Class Validation Results:\")\n",
    "    for class_id in val_metrics[\"class_metrics\"]:\n",
    "        class_name = reverse_label_map.get(class_id, f\"Class_{class_id}\")\n",
    "        cm = val_metrics[\"class_metrics\"][class_id]\n",
    "        print(\n",
    "            f\"         {class_name}: P={cm['precision']:.3f}, R={cm['recall']:.3f}, F1={cm['f1_score']:.3f}\"\n",
    "        )\n",
    "\n",
    "    # Performance comparison and overfitting detection\n",
    "    acc_diff = episode_accuracy - val_metrics[\"accuracy\"]\n",
    "    f1_diff = f1_score - val_metrics[\"f1_score\"]\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Reward Trends: Avg(10)={avg_reward_10:.2f}, Avg(100)={avg_reward_100:.2f}\")\n",
    "    print(\n",
    "        f\"Training: Îµ={eps_threshold:.3f}, LR={current_lr:.6f}, Memory={len(agent.memory)}\"\n",
    "    )\n",
    "    print(\"   \" + \"=\" * 80)\n",
    "\n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        print(f\"Updating target network at episode {i_episode+1}\")\n",
    "        agent.update_target_net()\n",
    "\n",
    "    # Save checkpoint every episode\n",
    "    checkpoint_filename = os.path.join(\n",
    "        checkpoint_dir, f\"checkpoint_episode_{i_episode}.pth\"\n",
    "    )\n",
    "    save_checkpoint(agent, i_episode, episode_rewards, checkpoint_filename)\n",
    "\n",
    "print(\"\\n--- DTQN Training Complete ---\")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(checkpoint_dir, \"final_model.pth\")\n",
    "save_checkpoint(agent, NUM_EPISODES - 1, episode_rewards, final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2f6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27310/1159732952.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "state = torch.load(\n",
    "    './checkpoints/checkpoint_episode_1.pth',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad868a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
